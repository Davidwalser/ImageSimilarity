%----------------------------------------------------------------
%
%  File    :  thesis.tex
%
%  Authors :  David Walser, Wien, Austria
% 
%  Created :  08 Feb 2022
% 
%  Changed :  08 Feb 2022
%
%  For suggestions and remarks write to: sebastian.ukleja@fh-campuswien.ac.at 
%----------------------------------------------------------------

% --- Setup for the document ------------------------------------

%Class for a book like style:
\documentclass[11pt,a4paper,oneside]{scrbook}
%For a more paper like style use this class instead:
%\documentclass[11pt,a4paper,oneside]{thesis}

%input encoding for windows in utf-8 needed for Ä,Ö,Ü etc..:
\usepackage[utf8]{inputenc}
%input encoding for linux: 
%\usepackage[latin1]{inputenc}
%input encoding for mac:
%\usepackage[applemac]{inputenc}

\usepackage[ngerman]{babel}
%for english use this instead:
%\usepackage[english]{babel}

%needed for font encoding
\usepackage[T1]{fontenc}

% want Arial? uncomment next two lines...
%\usepackage{uarial}
%\renewcommand{\familydefault}{\sfdefault}

%some formatting packages
\usepackage[bf,sf]{subfigure}
\renewcommand{\subfigtopskip}{0mm}
\renewcommand{\subfigcapmargin}{0mm}

%For better font resolution in pdf files
\usepackage{lmodern}

\usepackage{url}


%\usepackage{latexsym}

\usepackage{geometry} % define pagesize in more detail

% --- Settings for header and footer ---------------------------------
\usepackage{scrlayer-scrpage}
\clearscrheadfoot
\pagestyle{scrheadings}
\automark{chapter}

%Left header shows chapter and chapter name, will not display on first chapter page use \ihead*{\leftmark} to show on every page
\ihead{\leftmark} 	
%\ohead*{\rightmark}	%optional right header
\ifoot*{David Walser}		%left footer shows student name
\ofoot*{\thepage}		%right footer shows pagination
%---------------------------------------------------------------------

\usepackage{colortbl} % define colored backgrounds for tables

\usepackage{courier} %for listings
\usepackage{listings} % nicer code formatting
\lstset{basicstyle=\ttfamily,breaklines=true}

\usepackage{graphicx}
  \pdfcompresslevel=9
  \pdfpageheight=297mm
  \pdfpagewidth=210mm
  \usepackage[         % hyperref should be last package loaded
    pdftex, 		   % needed for pdf compiling, DO NOT compile with LaTeX
    bookmarks,
    bookmarksnumbered,
    linktocpage,
    pagebackref,
    pdfview={Fit},
    pdfstartview={Fit},
    pdfpagemode=UseOutlines,                 % open bookmarks in Acrobat
  ]{hyperref}
\DeclareGraphicsExtensions{.pdf,.jpg,.png}
\usepackage{bookmark}

\usepackage[title]{appendix}

\usepackage{wrapfig}
%paper format
\geometry{a4paper,left=30mm,right=25mm, top=30mm, bottom=30mm}

\setlength{\parskip}{3pt plus 1pt minus 0pt}       % vert. space before a paragraph

\setcounter{tocdepth}{1}        % lowest section level entered in ToC
\setcounter{secnumdepth}{2}     % lowest section level still numbered

%Start of your document beginning with title page
\begin{document}
\frontmatter

% --- Main Title Page ------------------------------------------------
\begin{titlepage}
\begin{picture}(50,50)
\put(-70,40){\hbox{\includegraphics{images/logo.png}}}
\end{picture}

\vspace*{-5.8cm}

\begin{center}

\vspace{6.2cm}

\hspace*{-1.0cm} {\LARGE \textbf{Bildähnlichkeitserkennung von Markenlogos mithilfe von Machine Learning \\}}
\vspace{0.2cm}
\hspace*{-1.0cm} Untertitel \\

\vspace{2.0cm}

\hspace*{-1.0cm} { \textbf{Masterarbeit\\}}

\vspace{0.65cm}

\hspace*{-1.0cm} Eingereicht in teilweiser Erfüllung der Anforderungen zur Erlangung des akademischen Grades: \\

\vspace{0.65cm}

\hspace*{-1.0cm} \textbf{Master of Science in Engineering\\}

\vspace{0.65cm}

\hspace*{-1.0cm} an der FH Campus Wien \\
\vspace{0.2cm}
\hspace*{-1.0cm} Studienfach: Software Design and Engineering \\

\vspace{1.6cm}

\hspace*{-1.0cm} \textbf{Autor:} \\
\vspace{0.2cm}
\hspace*{-1.0cm} David Walser \\

\vspace{0.7cm}

\hspace*{-1.0cm} \textbf{Matrikelnummer:}\\
\vspace{0.2cm}
\hspace*{-1.0cm} 01609388 \\

\vspace{0.7cm}

\hspace*{-1.0cm} \textbf{Betreuer:} \\
\vspace{0.2cm}
\hspace*{-1.0cm} FH-Prof. DI Dr. Igor Miladinovic \\

\vspace{0.7cm}

% Reviewer if needed:
%\hspace*{-1.0cm} \textbf{Reviewer: (optional)} \\
%\vspace{0.2cm}
%\hspace*{-1.0cm} Titel Vorname Nachname \\


\vspace{1.0cm}

\hspace*{-1.0cm} \textbf{Datum:} \\
\vspace{0.2cm}
\hspace*{-1.0cm} 02.02.2022 \\

\end{center}
\end{titlepage}

\newpage
\setcounter{page}{1}

\vspace*{16cm}

% --- Declaration of authorship ----------------------------------------------------
\hspace*{-0.7cm} \underline{Erklärung der Urheberschaft:}\\\\
Ich erkläre hiermit diese Masterarbeit eigenständig verfasst zu haben. Ich habe keine anderen Quellen, als die in der Arbeit gelisteten verwendet, noch habe ich jegliche unerlaubte Hilfe in Anspruch genommen\\\\
Ich versichere diese Masterarbeit in keinerlei Form jemandem Anderen oder einer anderen Institution zur Verfügung gestellt zu haben, weder in Österreich noch im Ausland.\\\\
Weiters versichere ich, dass jegliche Kopie (gedruckt oder digital) identisch ist.
\\\\\\
Datum: \hspace{6cm} Unterschrift:\\

% --- English Abstract ----------------------------------------------------
\cleardoublepage
\chapter*{Abstract}
(E.g. ``This thesis investigates...'')


% --- German Abstract ----------------------------------------------------

\cleardoublepage
\chapter*{Kurzfassung}
(Z.B. ``Diese Arbeit untersucht...'')

% --- Abbrevations ----------------------------------------------------
\newpage\noindent
\chapter*{Abkürzungen}
\vspace{0.65cm}

\begin{table*}[htbp]
		\begin{tabular}{ll}
			ÖPA & Österreichisches Patentamt \\
			KNN & künstliches neuronales Netzwerk \\
			CNN & convolutional neural network \\
			ARP & Address Resolution Protocol \\
			GPRS & General Packet Radio Service \\
			GSM  &  Global System for Mobile communication \\
			WLAN & Wireless Local Area Network \\
		\end{tabular}
\end{table*}

% --- Key terms ----------------------------------------------------
\newpage
\chapter*{Schlüsselbegriffe}
\vspace{0.65cm}

\begin{itemize}
	\setlength{\itemsep}{0pt}
	\item[] GSM
	\item[] Mobilfunk
	\item[] Zugriffsverfahren
\end{itemize}

% --- Table of contents autogenerated ------------------------------------
\newpage
\tableofcontents
\thispagestyle{empty}

% --- Begin of Thesis ----------------------------------------------------
\mainmatter
\chapter{Einführung}
\label{chap:intro}
\section{Problembeschreibung}
\label{sec:Problembeschreibung}
Für uns Menschen ist es eine ziemlich einfache Aufgabe zu ermitteln ob ein Bild ähnlich zu einem anderen ist oder nicht. 
Wir erkennen alle Möglichen Merkmale eines Bildes, wie Farben, Texte oder Muster, ohne große Schwierigkeiten.
Es stellt jedoch eine Herausforderung dar, wenn ein Bild mit 400.000 anderen Bildern verglichen und auf ähnlichkeit geprüft werden soll.

Im Jahre 2020 wurden 6260 neue Marken beim österreichischen Patentamt angemeldet \cite{oepastatistik2020}.
Die meisten dieser Marken werden in Kombination mit einem Bild, auch Logo genannt, registriert.
Damit es bei einer Neuanmeldung nicht zu einer unmittelbaren Verwechslungsgefahr mit bereits bestehenden Marken kommt, bietet das österreichische Patentamt einen Dienst an, bei dem Daten zu einer Marke angegeben werden, und überprüft wird, ob es Ähnlichkeiten mit bereits angemeldeten Marken gibt \cite{oepamarkenaehnlichkeitsrecherche}. 
Ein Hauptbestandteil dieser Ähnlichkeitsrecherche ist die Überprüfung von Ähnlichkeiten der Logos. 

\section{Motivation und Ziel}
\label{sec:motivationundziel}
Machine Learning ist ein aufkommendes und zukunftsweisendes Thema.
Laut einer Studie aus 2017 wurde ein Wachstum des machine learning Marktes von 1.03 Milliarden \$ in 2016 auf 8.81 Milliarden \$ im Jahre 2022 erwartet, was einer Wachstumsrate von 44.1\% entsrpicht \cite{researchandmarkets}. 
Technologisch gesehen ist der mit dieser Masterarbeit verbundene Prototyp eine große Herausforderung, da zur Umsetzung allerneuste Technologien und Frameworks benötigt werden.
Eine weitere Herausforderung wird es sein, wie genau die vom österreichischen Patentamt dankenswerter weise zur Verfügung gestellten Daten zu analysieren und kategorisieren sind.
Ziel dieser Masterarbeit ist es das Patentamt bei der Ähnlichkeitsrecherche zu unterstützen, in dem ein Prototyp entwickelt wird, welcher Ähnlichkeiten bei Bildern erkennt.
Außerdem soll diese Masterarbeit einen Überblick über Machine Learning, mit Fokus auf Bildverarbeitung, enthalten.
Daraus ergibt sich die folgende Forschungsfrage \begin{quotation}Welche Unterschiede weisen verschiedene ML Algorithmen auf, im Bezug auf Erkennungsrate einer Ähnlichkeitsüberprüfung von Bildern?\end{quotation} zu beantworten.

\chapter{Machine learning}
\label{chap:machinelearning}
Für viele Firmen ist machine Learning bereits der meist benutzte Bereich aus dem Feld der künstlichen Intelligenz \cite{imageprocessingnanonets}.
Machine Learning ist die Wissenschaft und Kunst Computern das Lernen anhand von Daten zu ermöglichen \cite{geron2019hands-on} und ist ein Anwendungsgebiet von künstlicher Intelligenz welches bereits seit vielen Jahren die Forschung und Wirtschaft unterstützt \cite{datasolutml}. 
"Machinelles Lernen ist ein Oberbegriff für die "künstliche" Generierung von Wissen aus Erfahrung: Ein künstliches System lernt aus Beispielen und kann diese nach Beendigung der Lernphase verallgemeinern." \cite{wikipediaml}
Muster und Gesetzmäßigkeiten werden aus den Trainignsdaten erkannt, woraus ein staistisches Modell erzeug wird \cite{wikipediaml}.
Dieser Prozess wird als Modelltraining bezeichnet und ist ein iterativer Prozess, welcher oft mehrfach durchlaufen wird, bis die Qualität des Ergebnis zufriedenstellend ist \cite{datasolutml}.
Aus dem Erlernen und Analysieren der historischen Daten kann ein Ergebnis für neue und unbekannte Daten prognostiziert werden, ohne explizit darauf programmiert zu sein \cite{techtargetml}. 
\begin{figure}[htbp]
	\centering
		\includegraphics[height=5cm]{images/machine_learning.png}
	\caption{Machine Learning nimmt Eingabedaten mit Beispielen und lernt daraus, um für die Zukunft Prognosen zu machen \cite{datasolutml}}
	\label{fig:machine_learning}
\end{figure}

Ein Alltag ohne dem Interagieren mit Machine Learning ist heutzutage kaum mehr wegzudenken.
Bei der Benutzung von sozialen Medien, online Shopping oder Bankdiensten kommt Machine Learning zum Einsatz \cite{oracleml} und bereits seit den 1990er Jahren beeinflusst Machine Learning in Form des Spam Filters das Leben vieler \cite{geron2019hands-on}. 
Netflix bietet mithilfe von Machine Learning personalisierte Film und Serienempfehlungen an, und zusätzlich unterstützt Machine Learning bei der Optimierung der Produktion von Filmen und TV Shows \cite{netflixml}.  
Facebooks Algorithmus kann bereits mit 100 bis 150 Likes die Persöhnlichlkeit einer Person genauer beschreiben als deren Familienmitglieder oder Freunde \cite{facebookml}. 
Die Grundlage für Machine Learning bilden Algorithmen, welche sich in folgende Arten aufteilen lassen \cite{oracleml}: 
\begin{itemize}
	\item supervised learning
	\item unsupervised learning
	\item semi-supervised learning
	\item reinforcement learning
\end{itemize}

\section{Supervised Machine Learning}
\label{sec:supervised}
Supervised Machine Learning, im Deutschen übersetzt überwachtes Lernen, ist die am häufigsten angewendete Algorithmusart \cite{oracleml}.
Ähnlich wie in der Schule wenn unter Aufsicht des Lehrers oder der Lehrerin geprüft wird, ob ein Problem richtig oder falsch gelöst wird, ist die Situation bei supervised Machine Learning Algorithmen.
Dem Algorithmus wird ein gelabelter Datensatz zum Lernen zur Verfügung gestellt, somit weiß der Algorithmus für jeden Datensatz die richtige Lösung \cite{intellipaatml}. 
Ein gelabelter Datensatz kann z.B. ein Bild von einem Tier sein, wobei hier zusätzlich auch die Information über ein Feature mitgegeben wird, wie z.B. die Art des Tieres oder das Gewicht des Tieres (siehe Abbildung ~\ref{fig:labeled_vs_unlabeled}).
Das Label ist die Information über ein Feature welche der Algorithmus später vorhersagen will. \cite{grokkingml}
\begin{figure}[htbp]
	\centering
		\includegraphics[height=4cm]{images/labeled_vs_unlabeled.png}
	\caption{Labeled vs unlabeled Data \cite{grokkingml}}
	\label{fig:labeled_vs_unlabeled}
\end{figure}
Folgende Algorithmen sind Beispiele für supervised Learning \cite{geron2019hands-on}:
\begin{itemize}
	\item k-Nearest Neighbors
	\item Naive Bayes
	\item Linear Regression
	\item Logistic Regression
	\item Support Vector Machines (SVMs)
	\item Decision Trees und Random Forests
	\item Neuronale Netzwerke (wobei diese auch unsupervised oder semisupervised sein können) 
\end{itemize}
Klassifizierung und Regression sind klassische Anwendungsgebiete für supervised learning \cite{geron2019hands-on}.
\subsection{Klassifizierung}
Bei Klassifizierungsproblemen geht es darum einen Status vorherzusagen \cite{grokkingml}, wie z.B. zu welcher Klasse oder Gruppe die Inputdaten gehören \cite{intellipaatml}. 
Der Spam Filter ist ein gutes Beispiel für Klassifizierung, hierbei handelt es sich um zwei Klassen: Spam und nicht Spam.
Der Algorithmus bekommt E-Mails zum Lernen, welche als Spam E-Mail oder normale E-Mail gelabelt sind, um somit für neue E-Mails herauszufinden, ob diese Spam E-Mails sind \cite{geron2019hands-on}. 
\subsection{Regression}
Regression ist ein Fachgebiet der Statistik und ist eine Methode um die Beziehung zwischen unabhängigen Variablen oder Merkmalen und einer abhänigen Variable oder einem Ergebnis zu verstehen.
Sobald die Beziehung zwischen unabhängigen und abhängigen Variablen geschätzt wurde, können die Ergebnisse vorhergesagt werden. \cite{unsupervisedibm}
Bei Regressionsproblemen geht es um kontinuierliche Daten \cite{intellipaatml} und darum eine Zahl vorherzusagen, wie z.B. das Vorhersagen von Aktienkursen \cite{grokkingml} oder von Grundstückspreisen \cite{intellipaatml}.

\section{Unsupervised Machine Learning}
\label{sec:unsupervised}
Bei unsupervised Machine Learning, im Deutschen übersetzt unüberwachtes Lernen, handelt es sich um den Ansatz mit Datensätzen zu lernen, welche kein Label besitzen \cite{geron2019hands-on}.
Dies wird auch als selbst organisiertes Lernen bezeichnet \cite{intellipaatml}, da der Algorithmus ohne einen Lehrer oder eine Lehrerin lernt \cite{geron2019hands-on}. 
Da es sich hierbei um ungelabelte Datensätze handelt, besitzen diese nicht die Zielinformation, welche vorhergesagt werden soll \cite{grokkingml} und somit werden Zusammenhänge in den Daten \cite{unsuperviseddatasolut}, versteckte Muster oder Datengruppierungen von unsupervised Algorithmen erkennt, ohne dass menschliches Eingreifen erforderlich ist \cite{unsupervisedibm}.
\begin{figure}[htbp]
	\centering
		\includegraphics[height=4cm]{images/unsupervised.png}
	\caption{"Model trainiert ohne Zielvariable und findet eigenständig Muster und Zusammenhänge in den Daten" \cite{unsuperviseddatasolut}}
	\label{fig:unsupervised}
\end{figure}
Die Fähigkeit, Ähnlichkeiten und Unterschiede in Informationen zu entdecken, macht sie zur idealen Lösung für die explorative Datenanalyse, Kundensegmentierung und Bilderkennung.
Folgende Algorithmen sind Beispiele für unsupervised Learning \cite{geron2019hands-on}:
\begin{itemize}
	\item K-Means
	\item DBSCAN
	\item Hierarchical Cluster Analysis (HCA)
	\item Principal Component Analysis (PCA)
	\item Kernel PCA
	\item Locally-Linear Embedding (LLE)
	\item Apriori
	\item Eclat
\end{itemize}
Clustering, Assoziationsanalyse und Dimensionalitätsreduktion sind die drei Hauptaufgaben von unsupervised Machine Learning \cite{unsupervisedibm}.
\subsection{Clustering}
Beim Clustering geht es darum, die Population oder die Datenpunkte in eine Reihe von Gruppen aufzuteilen, so dass die Datenpunkte in denselben Gruppen anderen Datenpunkten in derselben Gruppe ähnlicher und den Datenpunkten in anderen Gruppen unähnlicher sind \cite{clusteringgeeks}.
Es werden ungelabelte Daten auf der Grundlage ihrer Ähnlichkeiten oder Differenzen in verschiedene Gruppen aufgeteilt \cite{unsupervisedibm}. 
Anwendungsgebiete für Clustering sind beispielsweise Bücher die je nach Titel und Inhalt in verschiedene Gruppen eingeteilt werden oder Pflanzen und Tiere welche in Spezies aufgeteilt werden (siehe Abbildung ~\ref{fig:unsupervised}) \cite{clusteringgeeks}.
\subsection{Assoziationsanalyse}
Die Assoziationsanalyse ist eine Methode um herauszufinden welche Muster (Beziehungen, Korrelationen, Strukturen, ...) es in den Datensätzen gibt \cite{associationmedium}.
Diese Methode wird häufig für Warenkorbanalysen verwendet, um ein besseres Verständis über die Beziehung zwischen den Produkten zu bekommen. 
Beispiele davon sind z.B. auf Amazon die "Kunden, die diesen Artikel gekauft haben, kauften auch:" Anzeige oder die Spotify "Discover Weekly" Playlist. \cite{unsupervisedibm}
\subsection{Dimensionalitätsreduktion}
Während mehr Daten grundsätzlich zu genaueren Ergebnissen führen können, so kann dies auch die Leistung von Algorithmen für machine Learning beeinträchtigen (z.B. overfitting) und die Visualisierung von Datensätzen erschweren \cite{unsupervisedibm}.
Bei der Dimensionalitätsreduktion geht es darum, die Variablen in den Daten auf die wesentlichen und zielführenden zu beschränken (z.B. werden redundante oder noise Features entfernt) \cite{unsuperviseddatasolut}, wobei die Integrität der Daten so weit wir möglich erhalten bleiben soll \cite{unsupervisedibm}.
Es kann für das bereinigen von Daten oder auch für das Hervorheben von Features verwendet werden, da die Daten dabei von hochdimensionalem Featureraum in niedrigdimensionalem Featureraum transformiert werden \cite{dimensionalityneptune}.

\section{Semi-supervised Learning}
\label{sec:semisupervised}
Um die Schwierigkeiten vom Erstellen von großen gelabelten Datensätzen entgegenzuwirken gibt es eine Methode bei der ein kleiner Anteil gelabelte Daten, der Großteil jedoch ungelabelte Daten sind.
Dieese Methode wird als semi-supervised Learning bezeichnet, welche die Benefits von unsupervised und supervised kombiniert. \cite{semisuperviseddatarobot}
Der Algorithmus wird initial mit den wenig gelabelten Daten trainiert und kann somit iterativ mehr und mehr an die ungelabelten Daten angewandt werden.
Self-training und Co-training sind zwei Ansätze für semi-supervised learning. \cite{semisupervisedalexsoft}
\subsection{Self-training}
Self-training ist eines der einfachsten Beispiele für semi-supervised learning und ist ein Prozedere einen supervised learning Ansatz in semi-supervised umzuwandeln \cite{semisupervisedalexsoft}.
Der straightforward Ansatz wird anhand folgendem Beispiel erklärt:
\begin{enumerate}
	\item Die gelabelten Daten werden für das Trainieren des Models herangenommen \cite{selftrainingtowardsdatasience}.
	\item Dieses Model wird dann für die Vorhersage von ungelabelten Daten verwendet \cite{selftrainingtowardsdatasience}.
	\item Es werden Ergebnisse, welche dem zuvor bestimmten Kriterium entsprechen (z.B. >90\% accuracy), mit pseudo-labels verzehrt und mit den bereits gelabelten Daten kombiniert \cite{selftrainingtowardsdatasience}.
	\item Das Model wird nun mit dem neuen Pool an gelabelten Daten trainiert \cite{selftrainingtowardsdatasience}.
	\item Der ganze Prozess wird nun durchiteriert bis entweder alle Daten gelabelt sind oder die spezifizierte Maximalanzahl an Iterationen erreicht wird \cite{selftrainingtowardsdatasience}.
\end{enumerate}
Die Performance von dem Self-training Ansatz variiert von Datensatz zu Datensatz und es gilt abzuwägen ob sie im Vergeleich zu dem supervised Ansatz eine Verbesserung erzielt \cite{semisupervisedalexsoft}. 
\subsection{Co-training}
Co-training ist eine verbesserte Version von Self-Training, die zum Einsatz kommt, wenn nur wenig gelabelte Daten verfügbar sind \cite{semisupervisedalexsoft}.
Bei dieser Methode benötigt es zwei Sichten auf die Daten \cite{cotrainingwiki} und basierend darauf werden zwei individuelle Klassifizierer trainiert \cite{semisupervisedalexsoft}.
Die zwei Ansichten sind verschiedene Gruppen von Features, welche jeweils Informationen für jede Instanz beinhalten \cite{semisupervisedalexsoft}.
Dies bewirkt dass beide Ansichten unabhängig sind und sie alleinstehend die Klasse einer Instanz vorhersagen können\cite{cotrainingwiki}.
Ein Anwendugsgebiet für Co-Training könnte die Klassifizierung von Webinhalten sein.
Der Inhalt einer Webseite kann in zwei Ansichten aufgeteilt werden: eine mit Wörtern, und die andere mit Verweistexten der Links, welche zu dieser Seite führen. \cite{semisupervisedalexsoft}
Der Ablauf eines Co-Trainings sieht wie folgt aus:
\begin{enumerate}
	\item Für jede Ansicht werden die seperaten Models mit den gelabelten Daten trainiert \cite{semisupervisedalexsoft}.
	\item Die ungelabelten Daten werden hinzugefügt und mit pseudo-labels versehen \cite{semisupervisedalexsoft}.
	\item Die beiden Klasifizierer trainieren sich gegenseitig mit den pseudo-labels und es wird das höchste Konfidenzniveau angestrebt. Wenn z.B. der erste Klassifizierer das Label für einen Datensatz vorhersagt, während der andere einen Fehler macht, so werden die vom ersten Klassifizierer zugewiesenen pseudo-labels jene vom zweiten überschreiben und vice-versa. \cite{semisupervisedalexsoft}
	\item Zuletzt werden die beiden geupdaten Klassifizierer in zu einem kombiniert \cite{semisupervisedalexsoft}.
\end{enumerate}

\section{Reinforcement Learning}
\label{sec:reinforcement}
Reinforcement Learning, im Deutschen übersetzt Bestärkendes oder Verstärkendes Lernen, ist eine immer beliebter werdende Methode und  befasst sich damit intelligente Lösungen für komplexe Steuerungsprobleme zu finden \cite{reinforcementat}.
Das lernende System, welches in diesem Kontext \textit{Agent} genannt wird, beobachtet das Umfeld und führt dann Aktionen aus, für die es entweder Belohnungen oder Bestrafungen bekommt \cite{geron2019hands-on}.
\begin{wrapfigure}{r}{0.5\textwidth}
	\centering
		\includegraphics[height=6cm]{images/reinforcement.png}
	\caption{Beispiel von Reinforcement Learning \cite{reinforcementdatasolut}}
	\label{fig:reinforcement}
\end{wrapfigure}
Hierbei erlernt der Agent eigenständig welche Aktion für welche Situation am besten geeignet ist, um die Belohnungsfunktion zu maximieren \cite{reinforcementdatasolut}.
Im Gegensatz zu supervised oder unsupervised learning werden beim Reinforcement Learning vorab keine Daten benötigt.
Die Daten werden während den Trial-and-Error Trainingsdurchläufen der Simulationsumgebung generiert und gelabelt.
Das Ziel von Reinforcement Learning ist es eine bestmöglichste Policy zu erreichen. \cite{reinforcementat}
Als Policy wird die Strategie bezeichnet, welche der Agent ausführt und gibt an welche Aktion als nächstes ausgeführt werden soll\cite{reinforcementdatasolut} um die Belohnung zu maximieren \cite{reinforcementat}.
Reinforcement Learning anhand eines Beispieles:
Die Katze (siehe Abbildung , welche in diesem Beispiel der Agent ist, befindet sich im Haus (Umgebung) und kann die zwei Zustände sitzen oder bewegen haben.
Wenn die Katze nun eine Aktion ausführt, so kann sie ihren Zustand ändern, wofür sie eine Belohnung oder eine Strafe erhalten kann.

\section{Neuronale Netzwerke}
\label{sec:neuronalnetworks}
Die Anfänge von künstlichen neuronalen Netzwerken machten 1943 der Neuropsychologe Warren MCCulloch und der Mathematiker Walter Pitts.
Sie stellten ein vereinfachtes Computermodell vor, welches wie biologische Neuronen in Tiergehirnen zusammenarbeitet \cite{geron2019hands-on}, um komplexe Aufgaben aus den Bereichen Statistik, Wirtschaft und Informatik lösen zu können \cite{nndatasolutbasic}.
Dies gilt als erste Architektur für künstliche neuronale Netzwerke und seither wurden viele weitere Architekturen entwicklet. \cite{geron2019hands-on}
"Künstliche neuronale Netze, auch künstliche neuronale Netzwerke, kurz: KNN (englisch artificial neural network, ANN), sind Netze aus künstlichen Neuronen." \cite{nnwiki}
Der Ursprung von künstlichen Neuronen sind die biologische Neuronen, welche in tierischen Gehirnen zu finden sind.
Neuronen kommunizieren in dem sie kurze elektrische Impulse über Synapsen versenden, bzw. empfangen.
Erhält ein Neuron eine ausreichende Anzahl an Signalen innerhalb weniger Millisekunden, so feuert dies eigene Signale weiter.
Die einzelnen Neuronen sind in einem Netzwerk mit Milliarden von anderen Neuronen verbunden, in dem sie in fortlaufenden Layern eingegliederd sind (siehe Abbildung ~\ref{fig:biological_nn}). \cite{geron2019hands-on}
\begin{figure}[htbp]
	\centering
		\includegraphics[height=4cm]{images/biological_nn.png}
	\caption{Multiple Layer in einem biologischen neuronalen Netzwerk \cite{geron2019hands-on}}
	\label{fig:biological_nn}
\end{figure}
 
Künstliche neuronale Netzwerke spiegeln das Verhalten des menschlichen Gehirns wieder und ermöglichen es Computerprogrammen selbständig Muster zu erkennen und allgemeine Probleme zu lösen \cite{nnibm}. 
%\begin{wrapfigure}{l}{0.5\textwidth}
%	\centering
%		\includegraphics[height=5cm]{images/neural_network.png}
%	\caption{Einfache Veranschaulichung eines neuronalen Netzwerkes \cite{nnwiki}}
%	\label{fig:neuronal_network}
%\end{wrapfigure}
Künstliche neuronale Netzwerke können verschiedene Datenquellen wie Geräusche, Bilder, Texte, Tabellen oder Zeitreihen interpretieren, woraus sie Informationen extrahieren und Muster erkennen um später auf unbekannte Daten Vorhersagen treffen zu können.
Grundsätzlich weisen künstliche neuronale Netzwerke die Strukturen gerichteter Graphen auf, können aber je nach komplexität unterschiedlich aufgebaut sein. \cite{nndatasolutbasic}
Angelehnt an die Struktur eines biologischen neuronalen Netzwerkes besteht ein künstliches neuronales Netzwerk ebenfalls aus Neuronen, welche in Layern (Schichten) angeordnet sind.
Ein solches Netzwerk besteht aus einem Input-Layer, einem (oder mehreren) Hidden-Layer und einem Output-Layer (veranschaulicht in Abbildung ~\ref{fig:neuronal_network}), wobei jeder dieser Layer eine Vielzahl an Neuronen beinhaltet.
Desto komplexer das zu lösende Problem ist, umso mehr Layer werden benötigt. \cite{nnionos}
Der Input-Layer nimmt die eingegebenen Daten entgegen, verarbeitet und gewichtet diese, bevor sie an den Hidden-Layer weiter gegeben wird \cite{nndatasolutbasic}.
Der Hidden-Layer befindet sich zwischen Input und Output-Layer \cite{nndatasolutbasic} und kann aus einem oder mehreren Layern bestehen und ist der Layer, in dem die meisten Berechnungen stattfinden \cite{nnmedium}.
Auch in diesem Layer finden wieder Gewichtungen statt.
Sind mehere Layer im Hidden-Layer vorhanden, so geschieht das Gewichten pro Layer. \cite{nndatasolutbasic}
Die Ausgabewerte des letzten Hidden-Layers werden dem Output-Layer als Eingabewerte übergeben \cite{nnmedium}.
Der Output-Layer ist die letzte Schicht und beinhaltet die Entscheidung oder Vorhersagung des neuronalen Netzwerkes \cite{nndatasolutbasic}.
\begin{figure}[htbp]
	\centering
		\includegraphics[height=6cm]{images/neural_network.png}
	\caption{Einfache Veranschaulichung eines neuronalen Netzwerkes \cite{nnwiki}}
	\label{fig:neural_network}
\end{figure}
Eine angemessene Anzahl an Neuronen und eine passende Ativierungsfunktion sollte je nach Aufgabe gewählt werden. 
In den Neuronen werden Berechnungen getätigt \cite{nnpathmind} und jedes Neuron hat ein zugeordnetes Gewicht, wodurch sie unterschiedliche Wichtigkeiten erhalten \cite{nnionos}.
%In biologischen neuronalen Netzwerken agieren Synapsen wie Gewichte über die eingehenden Impulse \cite{GURESEN2011426}.
Im biologischen Kontext können Gewichte mit Synapsen verglichen werden \cite{GURESEN2011426}.
Kombiniert mit einer Übertragungsfunktion entscheidet das Gewicht über den Input eines Neurons \cite{nnionos}.
Bei den künstlichen neuronalen Netzwerken kombiniert ein Neuron die Eingangssignale mit zugeordneten Gewichten, welche die Bedeutung des Signals schwächen oder verstärken. 
Nach dem Aufsummieren wird das Ergebnis durch eine Aktivierungsfunktion gegeben um zu berechnen ob, und mit welchem Ausmaß das Ausgangssignal weitergesendet wird.
Das Neuron wird als aktiviert bezeichnet, wenn es ein Ausgangssignal versendet. \cite{nnpathmind}
\begin{figure}[htbp]
	\centering
		\includegraphics[height=5cm]{images/neuron2.png}
	\caption{Aufbau eines Neurons \cite{nndatasolutbasic}}
	\label{fig:neuron}
\end{figure}

\subsection{Arten von neuronalen Netzwerken}
Es gibt viele verschiedene Arten von küntlichen neuronalen Netzwerken und es werden nun ein paar davon etwas näher erläutert.

\subsubsection{Preceptron}
Preceptron ist ein neuronales NEtzwerk mit nur einem Layer \cite{preceptrontowards}, welches im Bereich von supervised Learning Anwendung findet \cite{preceptronsimplilearn}.
Es ist ein linearer oder binärer Klassifizierer und wird verwendet um Daten in zwei Gruppen zu klassifizieren \cite{preceptrontowards}.
Ein Preceptron funktioniert folgendermaßen:
\begin{enumerate}
	\item Alle Eingangssignale werden mit ihren Gewichten multipliziert \cite{preceptrontowards}
	\item Nach dem multiplizieren wird alles Aufsummiert \cite{preceptrontowards}.
	\item Abschließend wird eine Aktivierungsfunktion angewendet, welche den Wert auf den gewünschten Wert, wie z.B. (0,1) mapt \cite{preceptrontowards}.
\end{enumerate}

\subsubsection{Feed forward neuronale Netzwerke}
Ein Preceptron ist eine From von Feed forward neuronalen Netzwerken, welche die einfachste Form von neuronalen Netzwerken sind \cite{ffnndeepai}.
Informationen werden nur in eine Richtung, von Input-Layer über Hidden-Layer zum Ausgangs-Layer verarbeitet.
Abbildung ~\ref{fig:neural_network} veranschaulicht ein feed forward neuronales Netzwerk und die funktionsweise ist gleich wie bei Preceptrons.
Wenn es viele Layer zwischen dem Input und Output-Layer gibt, so wird es auch als deep feed forward neural network bezeichnet. \cite{ffnnat}

\subsubsection{Convolutional neuronale Netzwerke}
Convolutional neural networks sind eines der beliebtesten deep neural networks.
Der Name kommt von der mathematischen Linearfunktion convolution, welche auf Matrixen angewandt wird. \cite{cnnieee}
CNNs sind effizient mit 2D und 3D Eingabedaten und werden unter anderem für Objektdetektion bei Bildern verwendet \cite{nndatasolutbasic}.
Die Architektur ist unterschiedlich zu klassischen neuronalen Netzwerken, mehr dazu in Kapitel \ref{cnn}.

\subsubsection{Recurrent neuronale Netzwerke}
Wenn es um sequentielle oder zeitliche Daten geht so können feed forward neuronale Netzwerke nicht verwendet werden.
Es wird ein Mechanismus benötigt um historische Daten zu speichern und desshalb wurden Recurrent neuronale Netzwerke entwickelt.
In klassischen feed forward neuronalen Netzwerken sind alle Datenpunkte unabhängig von einander, was mit sequentiellen Daten, welche von vorherigen Daten abhängig sind, nicht funktioniert. \cite{recurrentnnmastery}
Recurrent neuronale Netzwerke haben ein Konzept mit dem sie Informationen über vorherige Daten speichern können.
Dieses Konzept wird Memory genannt. \cite{recurrentibm}

\subsection{Training bei Neuronalen Netzwerken}
Ein Vorteil von künstlichen neuronalen Netzwerken ist, dass beim Erstellen nicht alle Parameter spezifiziert werden müssen, da der Algorithmus anhand von Beispielen von selbst lernt \cite{deeplearningnn}.
Neuronale Netzwerke können grundsätzlich für jedes komplexe Problem verwendet werden, bei dem es sich um funktionale Beziehungen handelt. 
Es ist hierbei nicht notwendig die Art der Beziehung zu kennen, da das neuronale Netzwerk durch das Beobachten und iterativem anpassen der Parameter lernt \cite{neuralnettraining}.

Um zu verstehen wie gut ein solches Netzwerk für eine bestimmte Aufgabe performt kann die Verlustfunktion verwendet werden.
Zu Beginn wird ein neuronales Netzwerk mit zufälligen Gewichten versehen, was in einem schlecht performenden neuronalem Netzwerk resultiert. 
Das Ziel ist es die hohe Verlustfunktion durch das Trainieren des neuronalen Netzwerkes in eine niedrige zu verwandeln. \cite{nntowards}
Eine Methode für das fine-tuning von neuronalen Netzwerken ist Backpropagation.
Dabei handelt es sich um eine Methode zur Anpassung der Gewichte eines neuronalen Netzwerkes, welche als Grundlage die Fehlerquote der vorangegangenen Iterationen (bei neuronalen Netzwerken Epochen genannt) hernimmt. 
Durch das richtige adaptieren der Gewichte kann die Fehlerquote verringert und die Genauigkeit des Models erhöht werden. \cite{backpropagationguru}
Gewichte verstärken oder schwächen die Signale der Neuronen und geben die Wichtigkeit eines bestimmten Bereiches der Daten an.
Ein Neuron kann ein bestimmtes Muster erkennen und die Bedeutung dieses Muster für das Gesamtkonstrukt entscheidet sich je nach Gewicht \cite{nnohv}.

\subsection{Anwendungsbeispiel eines neuronalen Netzwerks}
Um ein besseres Verständis für neuronale Netzwerke zu bekommen folgt nun ein Anwendungsbeispiel mit kleinen Codesnipets.
Ziel ist es ein neuronales Netzwerk aufzubauen, welches ein Bild einer handgeschriebenen Zahl richtig klassifizieren kann.
Hierfür wird der MNIST Datensatz \footnote[1]{MNIST Datensatz erhältlich unter http://yann.lecun.com/exdb/mnist/} verwendet, welcher 60000 28 mal 28 Pixel große Graustufenbilder von handgeschriebenen Zahlen von 0 bis 9 beinhaltet.
Um den MNIST Datensatz zu laden wird Tensorflow und Keras verwendet (siehe Codesnippet \ref{lst:mnist}).
\begin{lstlisting}[frame=lines, caption=MNIST Datensatz in Python laden, captionpos=b, label = lst:mnist, language=Python, showstringspaces=false]
from tensorflow.keras.datasets import mnist
# load dataset
(trainX, trainy), (testX, testy) = mnist.load_data()
\end{lstlisting}
Die Bilder aus dem MNIST Datensatz sind in Abbildung ~\ref{fig:mnist_data} zu sehen.
\begin{figure}[htbp]
	\centering
		\includegraphics[height=3.5cm]{images/mnist_data.png}
	\caption{Beispielbilder aus dem MNIST Datensatz}
	\label{fig:mnist_data}
\end{figure}

Die Architektur des neuronalen Netzwerkes hat 784 (28*28) Neuronen im Input-Layer. 
Somit kann jeder Pixel eines Bildes an ein Neuron als Eingabedaten übergeben werden.
Der Hidden-Layer beinhaltet 15 Neuronen, wobei die Anzahl hier variieren kann.
Abgeleitet von den vorhandenen Klassen (0 bis 9) ergeben sich sich 10 Neuronen im Output-Layer.
Um diese Architektur mithilfe von Keras und Tensorflow in Pyhton nachzubilden können die Codezeilen aus dem Codesnippet \ref{lst:architecture_nn} verwendet werden.
\begin{lstlisting}[frame=lines, caption=Architektur des Neuronalen Netzwerkes, captionpos=b, label = lst:architecture_nn, language=Python, showstringspaces=false]
from keras.layers import Dense
from keras.models import Sequential
image_size = 784 # 28*28 Pixel
num_classes = 10 # Zahlen von 0 bis 9
model = Sequential()
model.add(Dense(units=15, activation='sigmoid', input_shape=(image_size,)))
model.add(Dense(units=num_classes, activation='softmax'))
model.summary()
\end{lstlisting}
Dense bedeuted dass es sich um ein vollständig verbundenes Netzwerk handelt, was bedeutet dass jedes Neuron des Input-Layers mit jedem Neuron aus dem nächsten Layer verbunden ist.
Dies ist in Abbildung  ~\ref{fig:mnist_neural_network} zu sehen, welche die Beschriebene Architektur des neuronalen Netzwerks veranschaulicht.
\begin{figure}[htbp]
	\centering
		\includegraphics[height=9cm]{images/mnist_neural_network.png}
	\caption{Architektur des Neuronalen Netzwerks \cite{nnarchitecture}}
	\label{fig:mnist_neural_network}
\end{figure}
Vor dem Compilieren und Trainieren des neuronalen Netzwerkes werden die Testdaten noch modifiziert, was im kompletten Codebeispiel im Anhang zu finden ist.
\begin{lstlisting}[frame=lines, caption=Model compilen und erlernen, captionpos=b, label = lst:model_compile_train, language=Python, showstringspaces=false]
model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['acc']) 
history = model.fit(x_train, y_train, batch_size=128, epochs=5, verbose=False, validation_split=.1)
loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)
\end{lstlisting}
Als Verlustfunktion wird hier die categorical crossentropy verwendet, da diese für Mehrklassenklassizierung, bei der ein Datensatz genau einer Klasse angehört, sehr geeignet ist \cite{categoricalcrossentropy}.
Stochastic Gradient Descent gehören zu den einfachsten Optimierer, weshalb sie in diesem Besipiel für das Model gewählt wurden.
\begin{figure}
\center
\subfigure[5 Epochen]{\label{fig:5_epochs}\includegraphics[width=70mm]{images/mnist_5_epochs.png}}
\subfigure[50 Epochen]{\label{fig:50_epoochs}\includegraphics[width=70mm]{images/mnist_50_epochs.png}}
\caption{Vergleich 5 und 50 Epochen}
\label{fig:5_vs_50_epochs}
\end{figure}
Für das Trainieren des Algorithmus wurden zum Vergleich einmal 5 und einmal 50 Epochen ausgewählt.
Wie in Abbildung ~\ref{fig:5_vs_50_epochs} zu sehen ist erreicht das Model nach 5 Epochen eine Genauigkeit von etwas mehr als  80\%, während es nach 50 Epochen eine Genauigkeit von fast 90\% erreicht.
Die Architektur und der Aufbau des neuronalen Netzwerkes könnte noch deutlich verändert und optimiert werden, jedoch dient dieses Beispiel zum Verständis.


\chapter{Bildbezogenes Machine Learning}
\label{sec:imagerelatedml}
Die Digitalisierung und Automatisierung von Abläufen nimmt auf der ganzen Welt rasant zu.
Bilverarbeitung im Kontext von Computern und machine Learning bezieht sich darauf wichtige und bedeutende Informationen aus Bildern zu extrahieren.
Da Bilder mittels unstrukturierten Daten repräsentiert werden, ist es weitaus schwieriger diese im Gegensatz zu strukturierten Daten wie Tabellen zu interpretieren.
Je nach Anwendung gibt es unterschiedliche Methoden und Algorithmen, welche verwendet werden können.
Die große Branche, welche zudem stetig wächst, wird bereits in verschiednen Bereichen wie Video Verarbeitung, Gesichtserkennung, Medizinisches Umfeld, Robotic Vision, Selbstfahrende Autos und vieles mehr.\cite{autonomouscarsimageprocessing}
Während Tesla bereits autonome und selbständig fahrende Autos verkauft, hat Apple Ende 2021 einen Techniker von Tesla angeheuert und plant 2024 selbstfahrende Autos auf den Markt zu bringen \cite{reutersapple}.
Bildverarbeitung und Bilderkennung spielen hierbei eine große Rolle, da Objekte wie Fahrspur, Ampel und andere Verkehrsteilnehmer richtig und zeitgerecht erkannt werden müssen \cite{autonomouscarsimageprocessing}.

Auch im medizinischen Bereich hat machine Learning einen großen Einfluss.
Neuronale Netzwerke, insbesondere deep learning Methoden wie Convolutional neural Networks (siehe Kapitel \ref{cnn}), werden bereits für medizinische Bildanalyse wie Bildsegmentierung, Klassifizierung und Problemvorhersagungen verwendet und unterstützden dabei medizinische Experten \cite{KE2019218}.
Durch das Analysieren von Röntgenbildern der Brust können mithilfe von machine Learning COVID-19 Patienten, mit einer Genauigkeit von 96.78\%, erkannt werden \cite{covidpaper}.

\section{Wie computer sehen}
\label{sec:howcomputersee}
Seit über 60 Jahren versuchen Wissenschaftler auf der ganzen Welt Maschinen beizubrignen, wie sie bedeutungsvolle Informationen aus visuellen Daten extrahieren können \cite{computervisioncnnhackernoon}.
Bereits im Jahre 1959 beschäftigten sich die Neurophysiologen David Hubel und Torsten Wiesel mit dem Thema Computer Vision, welches ein Teilbereich von künstlicher Intelligenz ist, und den Zweck verfolgt Systemen das erkennen von bedeutsamen Informationen aus Bildern oder Videos zu extrahieren \cite{computervisionibm,computervisioncnnhackernoon}.
Ihre Puplikation "Receptive fields of single neurons in the cat's striate cortex"\cite{computervisioncat} gilt als eines der Papers, welches am meisten Einfluss auf die Thematik genommen hat \cite{computervisionibm,computervisioncnnhackernoon}.
Dabei beschreiben sie ihre Experimente, bei denen sie Elektroden and den primären Bereich des visuellen Kortex von anesthisierten Katzen angeschlossen haben, und diese dabei beobachtet haben, während den Versuchtieren verschiedene Bilder gezeigt wurden.
Durch einen glücklichen Zufall sind sie zur Erkenntniss gekommen, dass es sowohl einfache, als auch komplexe Neuronen im primären visuellen Kortex gibt, und dass visuelle Verarbeitung immer mit simplen Strukturen wie Kanten und Rändern beginnt.
Dieser Ansatz findet Anwendung bei convolutional neural networks und ist im Wesentlichen das Grundprinzip von deep Learning. \cite{computervisioncnnhackernoon}
Bevor es tiefer in diese Materie geht, wird im folgenden Unterkapitel kurz definiert und veranschaulicht was ein Bild ist und wie ein Computer solch eines wahrnimmt.

\subsection{Was ist ein Bild?}
tbd.

\section{Bilderkennung und Klassifizierung}
\label{sec:recognitionandclassification}
tbd.

\section{Algorithmen für Bildähnlichkeitserkennung}
\label{sec:algorithmsimagesimilarity}

\subsection{SIFT}

\subsection{Convolutional Neuronale Netzwerke}
\label{cnn}
Seit den 1980er Jahren werden convolutional neuronale Netzwerke für visuelle Aufgaben verwendet \cite{10.1162/neco_a_00990}.

\chapter{Prototyp zur Bildähnlichkeitserkennung von Markenlogos}
\label{chap:prototype}

\section{Daten}
\label{sec:data}

\section{Bildvorverarbeitung}
\label{sec:imagepreprocessing}

\section{Algorithmus}
\label{sec:algorithm}





%\chapter{Examples}
%\label{chap:intro}
%Textkörper mit Bild
%
%\begin{figure}[htbp]
%	\centering
%		\includegraphics[height=5cm]{images/buecher.png}
%	\caption{Ein Stapel Bücher}
%	\label{fig:buecher}
%\end{figure}
%
%
%Textkörper Fortsetzung mit Verweis auf den wundervollen Stapel Bücher in Abbildung \ref{fig:buecher}. 
%
%
%\section{Unterkapitel 1}
%\label{sec:Unterkapitel1}
%
%Textkörper mit Formel:
%
%\begin{equation}
%U(j\omega)=\int^{\infty}_{-\infty}{u(t) \cdot e^{-j\omega t}dt}
%\label{form:form1}
%\end{equation}
%
%Textkörper Fortsetzung mit Verweis auf Formel \ref{form:form1}. Und nicht zu vergessen: es gibt auch noch eine tolle Abbildung in Kapitel \ref{chap:intro}, nämlich Abbildung \ref{fig:buecher}. 
%
%
%\subsection{Unter-Unterkapitel 11}
%\label{sec:UnterUnterkapitel11}
%
%Textkörper mit direktem Zitat und Seitenanzahl:
%``It would be very easy to show how technical or report writing differed from other writing'' \cite[p.~3]{young2002technical}.
%
%\subsection{Unter-Unterkapitel 12}
%\label{sec:UnterUnterkapitel12}
%
%Textkörper mit Referenzen:
%Für weiterführende Informationen zum wissenschaftlichen Schreiben siehe "J. Schimel, Writing Science" \cite{schimel2012writing}. Es wird empfohlen den Sprachleitfaden der FH Campus Wien \cite{alker2006} zu berücksichtigen und die Checkliste für wissenschafltiches Schreiben \cite{petz2018} zu verwenden. Beide Leitfäden sind im FH Portal zu finden.
%
%\chapter{Kapitel 2}
%\label{chap:back}
%
%Textkörper mit noch einem Bild
%
%\begin{figure}[htbp]
%	\centering
%		\includegraphics{images/birne}
%	\caption{Eine Glühbirne}
%	\label{fig:birne}
%\end{figure}
%
%
%
%\section{Unterkapitel 21}
%\label{sec:Unterkapitel21}
%
%Textkörper mit Tabelle.
%
%\begin{table*}[htbp]
%	\centering
%		\begin{tabular}{|l|c|r|}
%		\hline
%		\rowcolor[gray]{0.9}
%		Spalte 1 & Spalte 2 & Spalte 3 \\
%		\hline
%		Affen & Giraffen & Löwen \\
%		Apfel & Birnen & Bananen \\
%		Irgend & et & was \\
%		\hline	
%		\end{tabular}
%	\caption{Beispiel für eine Tabelle}
%	\label{tab:BeispielFuerEineTabelle}
%\end{table*}
%
%Man beachte die Gegenüberstellung in Tabelle \ref{tab:BeispielFuerEineTabelle}.
%
%%Online Tabellengenerator für Latex: https://www.tablesgenerator.com/
%
%\section{Unterkapitel 23}
%\label{sec:Unterkapite23}
%
%Aufzählungen:
%
%Nummeriert:
%
%\begin{enumerate}
%	\item Punkt 1
%	\item Punkt 2
%\end{enumerate}
%
%Mit Bullet Points:
%
%\begin{itemize}
%	\item Punkt 1
%	\item Punkt 2
%\end{itemize}
%
%Mit Beschreibungen:
%
%\begin{description}
%	\item[Item 1] das ist der 1.Punkt
%	\item[Item 2] und das der 2.
%\end{description}
%
%
%Auch Programmcodes können an entsprechender Stelle eingefügt werden, man beachte dazu auch Listing \ref{lst:conv}.
%
%% see also http://mirror.easyname.at/ctan/macros/latex/contrib/listings/listings.pdf for options
%
%\begin{lstlisting}[frame=lines, caption=Simple Listing, captionpos=b, label = lst:conv, language=C, showstringspaces=false]
%#include <stdio.h>
%int main()
%{
%	int i, n, t1 = 0, t2 = 1, nextTerm;
%
%	printf("Enter the number of terms: ");
%	scanf("%d", &n);
%
%	printf("Fibonacci Series: ");
%
%	for (i = 1; i <= n; ++i)
%	{
%		printf("%d, ", t1);
%		nextTerm = t1 + t2;
%		t1 = t2;
%		t2 = nextTerm;
%	}
%	return 0;
%}
%\end{lstlisting}
%
%Und zuguterletzt, Formeln mitten im Fliesstext, wie z.B. $a^2+b^2=c^2$, in einem Absatz.

%\newpage
%\chapter{Related Work}

\newpage
\chapter{Diskussion der Ergebnise}

\newpage
\chapter{Conclusio}

\newpage
\chapter{Ausblick}

\newpage

% --- Bibliography ------------------------------------------------------

%IEEE Citation [1]
\bibliographystyle{IEEEtran}
%for alphanumeric citation eg.: [ABC19]
%\bibliographystyle{alpha}

% List references I definitely want in the bibliography,
% regardless of whether or not I cite them in the thesis.

\newpage
\addcontentsline{toc}{chapter}{Bibliographie}
\bibliography{testBib}

\newpage

% --- List of Figures ----------------------------------------------------

\addcontentsline{toc}{chapter}{Abbildungen}
\listoffigures


% --- List of Tables -----------------------------------------------------

\newpage
\addcontentsline{toc}{chapter}{Tabellen}
\listoftables

% --- Appendix A -----------------------------------------------------

\newpage
\appendix
\backmatter
\begin{appendices}
\chapter{Appendix}
\begin{lstlisting}[frame=lines, caption=Vollständiger Code für ein neuronales Netzwerk das Handschriftliche Zahlen erkennt, captionpos=b, label = lst:mnist_example, language=Python, showstringspaces=false]
import keras
from tensorflow.keras.datasets import mnist
from matplotlib import pyplot as plt
from keras.layers import Dense
from keras.models import Sequential

# load dataset
(pic_train, label_train), (pic_test, label_test) = mnist.load_data()
# summarize loaded dataset
print('Train: X=%s, y=%s' % (pic_train.shape, label_train.shape))
print('Test: X=%s, y=%s' % (pic_test.shape, label_test.shape))
# plot first few images
fig, axes = plt.subplots(ncols=5, sharex=False, 
    sharey=True, figsize=(10, 4))
for i in range(5):
    axes[i].set_title(label_train[i])
    axes[i].imshow(pic_train[i], cmap='gray')
    axes[i].get_xaxis().set_visible(False)
    axes[i].get_yaxis().set_visible(False)
plt.show()

num_classes = 10 # Zahlen von 0 bis 9
image_size = 28*28 # Pixels

# Gives a new shape to an array without changing its data.
x_train = pic_train.reshape(pic_train.shape[0], image_size)
x_test = pic_test.reshape(pic_test.shape[0], image_size)

# Converts a class vector (integers) to binary class matrix.
y_train = keras.utils.np_utils.to_categorical(label_train, num_classes)
y_test = keras.utils.np_utils.to_categorical(label_test, num_classes)

model = Sequential()

model.add(Dense(units=15, activation='sigmoid', input_shape=(image_size,)))
model.add(Dense(units=num_classes, activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy', optimizer='sgd',metrics=['acc']) 
history = model.fit(x_train, y_train, batch_size=128, epochs=5, verbose=False, validation_split=.1)
loss, accuracy  = model.evaluate(x_test, y_test, verbose=False)

plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['training', 'validation'], loc='best')
plt.show()

print(f'Test loss: {loss:.3}')
print(f'Test accuracy: {accuracy:.3}')
\end{lstlisting}

\clearpage
\end{appendices}

\end{document}
