%----------------------------------------------------------------
%
%  File    :  thesis.tex
%
%  Authors :  David Walser, Wien, Austria
% 
%  Created :  08 Feb 2022
% 
%  Changed :  08 Feb 2022
%
%  For suggestions and remarks write to: sebastian.ukleja@fh-campuswien.ac.at 
%----------------------------------------------------------------

% --- Setup for the document ------------------------------------

%Class for a book like style:
\documentclass[11pt,a4paper,oneside]{scrbook}
%For a more paper like style use this class instead:
%\documentclass[11pt,a4paper,oneside]{thesis}

%input encoding for windows in utf-8 needed for Ä,Ö,Ü etc..:
\usepackage[utf8]{inputenc}
%input encoding for linux: 
%\usepackage[latin1]{inputenc}
%input encoding for mac:
%\usepackage[applemac]{inputenc}

\usepackage[ngerman]{babel}
%for english use this instead:
%\usepackage[english]{babel}

%needed for font encoding
\usepackage[T1]{fontenc}

% want Arial? uncomment next two lines...
%\usepackage{uarial}
%\renewcommand{\familydefault}{\sfdefault}

%some formatting packages
\usepackage[bf,sf]{subfigure}
\renewcommand{\subfigtopskip}{0mm}
\renewcommand{\subfigcapmargin}{0mm}

%For better font resolution in pdf files
\usepackage{lmodern}

\usepackage{url}

%\usepackage{latexsym}

\usepackage{geometry} % define pagesize in more detail

% --- Settings for header and footer ---------------------------------
\usepackage{scrlayer-scrpage}
\clearscrheadfoot
\pagestyle{scrheadings}
\automark{chapter}

%Left header shows chapter and chapter name, will not display on first chapter page use \ihead*{\leftmark} to show on every page
\ihead{\leftmark} 	
%\ohead*{\rightmark}	%optional right header
\ifoot*{David Walser}		%left footer shows student name
\ofoot*{\thepage}		%right footer shows pagination
%---------------------------------------------------------------------

\usepackage{colortbl} % define colored backgrounds for tables

\usepackage{courier} %for listings
\usepackage{listings} % nicer code formatting
\lstset{basicstyle=\ttfamily,breaklines=true}

\usepackage{graphicx}
  \pdfcompresslevel=9
  \pdfpageheight=297mm
  \pdfpagewidth=210mm
  \usepackage[         % hyperref should be last package loaded
    pdftex, 		   % needed for pdf compiling, DO NOT compile with LaTeX
    bookmarks,
    bookmarksnumbered,
    linktocpage,
    pagebackref,
    pdfview={Fit},
    pdfstartview={Fit},
    pdfpagemode=UseOutlines,                 % open bookmarks in Acrobat
  ]{hyperref}
\DeclareGraphicsExtensions{.pdf,.jpg,.png}
\usepackage{bookmark}

\usepackage[title]{appendix}

%paper format
\geometry{a4paper,left=30mm,right=25mm, top=30mm, bottom=30mm}

\setlength{\parskip}{3pt plus 1pt minus 0pt}       % vert. space before a paragraph

\setcounter{tocdepth}{1}        % lowest section level entered in ToC
\setcounter{secnumdepth}{2}     % lowest section level still numbered

%Start of your document beginning with title page
\begin{document}
\frontmatter

% --- Main Title Page ------------------------------------------------
\begin{titlepage}
\begin{picture}(50,50)
\put(-70,40){\hbox{\includegraphics{images/logo.png}}}
\end{picture}

\vspace*{-5.8cm}

\begin{center}

\vspace{6.2cm}

\hspace*{-1.0cm} {\LARGE \textbf{Bildähnlichkeitserkennung von Markenlogos mithilfe von Machine Learning \\}}
\vspace{0.2cm}
\hspace*{-1.0cm} Untertitel \\

\vspace{2.0cm}

\hspace*{-1.0cm} { \textbf{Masterarbeit\\}}

\vspace{0.65cm}

\hspace*{-1.0cm} Eingereicht in teilweiser Erfüllung der Anforderungen zur Erlangung des akademischen Grades: \\

\vspace{0.65cm}

\hspace*{-1.0cm} \textbf{Master of Science in Engineering\\}

\vspace{0.65cm}

\hspace*{-1.0cm} an der FH Campus Wien \\
\vspace{0.2cm}
\hspace*{-1.0cm} Studienfach: Software Design and Engineering \\

\vspace{1.6cm}

\hspace*{-1.0cm} \textbf{Autor:} \\
\vspace{0.2cm}
\hspace*{-1.0cm} David Walser \\

\vspace{0.7cm}

\hspace*{-1.0cm} \textbf{Matrikelnummer:}\\
\vspace{0.2cm}
\hspace*{-1.0cm} 01609388 \\

\vspace{0.7cm}

\hspace*{-1.0cm} \textbf{Betreuer:} \\
\vspace{0.2cm}
\hspace*{-1.0cm} FH-Prof. DI Dr. Igor Miladinovic \\

\vspace{0.7cm}

% Reviewer if needed:
%\hspace*{-1.0cm} \textbf{Reviewer: (optional)} \\
%\vspace{0.2cm}
%\hspace*{-1.0cm} Titel Vorname Nachname \\


\vspace{1.0cm}

\hspace*{-1.0cm} \textbf{Datum:} \\
\vspace{0.2cm}
\hspace*{-1.0cm} 02.02.2022 \\

\end{center}
\end{titlepage}

\newpage
\setcounter{page}{1}

\vspace*{16cm}

% --- Declaration of authorship ----------------------------------------------------
\hspace*{-0.7cm} \underline{Erklärung der Urheberschaft:}\\\\
Ich erkläre hiermit diese Masterarbeit eigenständig verfasst zu haben. Ich habe keine anderen Quellen, als die in der Arbeit gelisteten verwendet, noch habe ich jegliche unerlaubte Hilfe in Anspruch genommen\\\\
Ich versichere diese Masterarbeit in keinerlei Form jemandem Anderen oder einer anderen Institution zur Verfügung gestellt zu haben, weder in Österreich noch im Ausland.\\\\
Weiters versichere ich, dass jegliche Kopie (gedruckt oder digital) identisch ist.
\\\\\\
Datum: \hspace{6cm} Unterschrift:\\

% --- English Abstract ----------------------------------------------------
\cleardoublepage
\chapter*{Abstract}
(E.g. ``This thesis investigates...'')


% --- German Abstract ----------------------------------------------------

\cleardoublepage
\chapter*{Kurzfassung}
(Z.B. ``Diese Arbeit untersucht...'')

% --- Abbrevations ----------------------------------------------------
\newpage\noindent
\chapter*{Abkürzungen}
\vspace{0.65cm}

\begin{table*}[htbp]
		\begin{tabular}{ll}
			ÖPA & Österreichisches Patentamt \\
			ARP & Address Resolution Protocol \\
			GPRS & General Packet Radio Service \\
			GSM  &  Global System for Mobile communication \\
			WLAN & Wireless Local Area Network \\
		\end{tabular}
\end{table*}

% --- Key terms ----------------------------------------------------
\newpage
\chapter*{Schlüsselbegriffe}
\vspace{0.65cm}

\begin{itemize}
	\setlength{\itemsep}{0pt}
	\item[] GSM
	\item[] Mobilfunk
	\item[] Zugriffsverfahren
\end{itemize}

% --- Table of contents autogenerated ------------------------------------
\newpage
\tableofcontents
\thispagestyle{empty}

% --- Begin of Thesis ----------------------------------------------------
\mainmatter
\chapter{Einführung}
\label{chap:intro}
\section{Problembeschreibung}
\label{sec:Problembeschreibung}
Für uns Menschen ist es eine ziemlich einfache Aufgabe zu ermitteln ob ein Bild ähnlich zu einem anderen ist oder nicht. 
Wir erkennen alle Möglichen Merkmale eines Bildes, wie Farben, Texte oder Muster, ohne große Schwierigkeiten.
Es stellt jedoch eine Herausforderung dar, wenn ein Bild mit 400.000 anderen Bildern verglichen und auf ähnlichkeit geprüft werden soll.

Im Jahre 2020 wurden 6260 neue Marken beim österreichischen Patentamt angemeldet \cite{oepastatistik2020}.
Die meisten dieser Marken werden in Kombination mit einem Bild, auch Logo genannt, registriert.
Damit es bei einer Neuanmeldung nicht zu einer unmittelbaren Verwechslungsgefahr mit bereits bestehenden Marken kommt, bietet das österreichische Patentamt einen Dienst an, bei dem Daten zu einer Marke angegeben werden, und überprüft wird, ob es Ähnlichkeiten mit bereits angemeldeten Marken gibt \cite{oepamarkenaehnlichkeitsrecherche}. 
Ein Hauptbestandteil dieser Ähnlichkeitsrecherche ist die Überprüfung von Ähnlichkeiten der Logos. 

\section{Motivation und Ziel}
\label{sec:motivationundziel}
Machine Learning ist ein aufkommendes und zukunftsweisendes Thema.
Laut einer Studie aus 2017 wurde ein Wachstum des machine learning Marktes von 1.03 Milliarden \$ in 2016 auf 8.81 Milliarden \$ im Jahre 2022 erwartet, was einer Wachstumsrate von 44.1\% entsrpicht \cite{researchandmarkets}. 
Technologisch gesehen ist der mit dieser Masterarbeit verbundene Prototyp eine große Herausforderung, da zur Umsetzung allerneuste Technologien und Frameworks benötigt werden.
Eine weitere Herausforderung wird es sein, wie genau die vom österreichischen Patentamt dankenswerter weise zur Verfügung gestellten Daten zu analysieren und kategorisieren sind.
Ziel dieser Masterarbeit ist es das Patentamt bei der Ähnlichkeitsrecherche zu unterstützen, in dem ein Prototyp entwickelt wird, welcher Ähnlichkeiten bei Bildern erkennt.
Außerdem soll diese Masterarbeit einen Überblick über Machine Learning, mit Fokus auf Bildverarbeitung, enthalten.
Daraus ergibt sich die folgende Forschungsfrage \begin{quotation}Welche Unterschiede weisen verschiedene ML Algorithmen auf, im Bezug auf Erkennungsrate einer Ähnlichkeitsüberprüfung von Bildern?\end{quotation} zu beantworten.

\chapter{Machine learning}
\label{chap:machinelearning}
Machine Learning ist die Wissenschaft und Kunst Computern das Lernen anhand von Daten zu ermöglichen \cite{geron2019hands-on} und ist ein Anwendungsgebiet von künstlicher Intelligenz welches bereits seit vielen Jahren die Forschung und Wirtschaft unterstützt \cite{datasolutml}. 
"Machinelles Lernen ist ein Oberbegriff für die "künstliche" Generierung von Wissen aus Erfahrung: Ein künstliches System lernt aus Beispielen und kann diese nach Beendigung der Lernphase verallgemeinern." \cite{wikipediaml}
Muster und Gesetzmäßigkeiten werden aus den Trainignsdaten erkannt, woraus ein staistisches Modell erzeug wird \cite{wikipediaml}.
Dieser Prozess wird als Modelltraining bezeichnet und ist ein iterativer Prozess, welcher oft mehrfach durchlaufen wird, bis die Qualität des Ergebnis zufriedenstellend ist \cite{datasolutml}.
Aus dem Erlernen und Analysieren der historischen Daten kann ein Ergebnis für neue und unbekannte Daten prognostiziert werden, ohne explizit darauf programmiert zu sein \cite{techtargetml}. 
\begin{figure}[htbp]
	\centering
		\includegraphics[height=5cm]{images/machine_learning.png}
	\caption{Machine Learning nimmt Eingabedaten mit Beispielen und lernt daraus, um für die Zukunft Prognosen zu machen \cite{datasolutml}}
	\label{fig:machine_learning}
\end{figure}

Ein Alltag ohne dem Interagieren mit Machine Learning ist heutzutage kaum mehr wegzudenken.
Bei der Benutzung von sozialen Medien, online Shopping oder Bankdiensten kommt Machine Learning zum Einsatz \cite{oracleml} und bereits seit den 1990er Jahren beeinflusst Machine Learning in Form des Spam Filters das Leben vieler \cite{geron2019hands-on}. 
Netflix bietet mithilfe von Machine Learning personalisierte Film und Serienempfehlungen an, und zusätzlich unterstützt Machine Learning bei der Optimierung der Produktion von Filmen und TV Shows \cite{netflixml}.  
Facebooks Algorithmus kann bereits mit 100 bis 150 Likes die Persöhnlichlkeit einer Person genauer beschreiben als deren Familienmitglieder oder Freunde \cite{facebookml}. 
Die Grundlage für Machine Learning bilden Algorithmen, welche sich in folgende Arten aufteilen lassen \cite{oracleml}: 
\begin{itemize}
	\item supervised learning
	\item unsupervised learning
	\item semi-supervised learning
	\item reinforcement learning
\end{itemize}

\section{Supervised Machine Learning}
\label{sec:supervised}
Supervised Machine Learning, im Deutschen übersetzt überwachtes Lernen, ist die am häufigsten angewendete Algorithmusart \cite{oracleml}.
Ähnlich wie in der Schule wenn unter Aufsicht des Lehrers oder der Lehrerin geprüft wird, ob ein Problem richtig oder falsch gelöst wird, ist die Situation bei supervised Machine Learning Algorithmen.
Dem Algorithmus wird ein gelabelter Datensatz zum Lernen zur Verfügung gestellt, somit weiß der Algorithmus für jeden Datensatz die richtige Lösung \cite{intellipaatml}. 
Ein gelabelter Datensatz kann z.B. ein Bild von einem Tier sein, wobei hier zusätzlich auch die Information über ein Feature mitgegeben wird, wie z.B. die Art des Tieres oder das Gewicht des Tieres (siehe Abbildung ~\ref{fig:labeled_vs_unlabeled}).
Das Label ist die Information über ein Feature welche der Algorithmus später vorhersagen will. \cite{grokkingml}
\begin{figure}[htbp]
	\centering
		\includegraphics[height=3cm]{images/labeled_vs_unlabeled.png}
	\caption{Labeled vs unlabeled Data \cite{grokkingml}}
	\label{fig:labeled_vs_unlabeled}
\end{figure}
Folgende Algorithmen sind Beispiele für supervised Learning \cite{geron2019hands-on}:
\begin{itemize}
	\item k-Nearest Neighbors
	\item Naive Bayes
	\item Linear Regression
	\item Logistic Regression
	\item Support Vector Machines (SVMs)
	\item Decision Trees und Random Forests
	\item Neuronale Netzwerke (wobei diese auch unsupervised oder semisupervised sein können) 
\end{itemize}
Klassifizierung und Regression sind klassische Anwendungsgebiete für supervised learning \cite{geron2019hands-on}.
\subsection{Klassifizierung}
Bei Klassifizierungsproblemen geht es darum einen Status vorherzusagen \cite{grokkingml}, wie z.B. zu welcher Klasse oder Gruppe die Inputdaten gehören \cite{intellipaatml}. 
Der Spam Filter ist ein gutes Beispiel für Klassifizierung, hierbei handelt es sich um zwei Klassen: Spam und nicht Spam.
Der Algorithmus bekommt E-Mails zum Lernen, welche als Spam E-Mail oder normale E-Mail gelabelt sind, um somit für neue E-Mails herauszufinden, ob diese Spam E-Mails sind \cite{geron2019hands-on}. 
\subsection{Regression}
Regression ist ein Fachgebiet der Statistik und ist eine Methode um die Beziehung zwischen unabhängigen Variablen oder Merkmalen und einer abhänigen Variable oder einem Ergebnis zu verstehen.
Sobald die Beziehung zwischen unabhängigen und abhängigen Variablen geschätzt wurde, können die Ergebnisse vorhergesagt werden. \cite{unsupervisedibm}
Bei Regressionsproblemen geht es um kontinuierliche Daten \cite{intellipaatml} und darum eine Zahl vorherzusagen, wie z.B. das Vorhersagen von Aktienkursen \cite{grokkingml} oder von Grundstückspreisen \cite{intellipaatml}.

\section{Unsupervised Machine Learning}
\label{sec:unsupervised}
Bei unsupervised Machine Learning, im Deutschen übersetzt unüberwachtes Lernen, handelt es sich um den Ansatz mit Datensätzen zu lernen, welche kein Label besitzen \cite{geron2019hands-on}.
Dies wird auch als selbst organisiertes Lernen bezeichnet \cite{intellipaatml}, da der Algorithmus ohne einen Lehrer oder eine Lehrerin lernt \cite{geron2019hands-on}. 
Da es sich hierbei um ungelabelte Datensätze handelt, besitzen diese nicht die Zielinformation, welche vorhergesagt werden soll \cite{grokkingml} und somit werden Zusammenhänge in den Daten \cite{unsuperviseddatasolut}, versteckte Muster oder Datengruppierungen von unsupervised Algorithmen erkennt, ohne dass menschliches Eingreifen erforderlich ist \cite{unsupervisedibm}.
\begin{figure}[htbp]
	\centering
		\includegraphics[height=4cm]{images/unsupervised.png}
	\caption{"Model trainiert ohne Zielvariable und findet eigenständig Muster und Zusammenhänge in den Daten" \cite{unsuperviseddatasolut}}
	\label{fig:unsupervised}
\end{figure}
Die Fähigkeit, Ähnlichkeiten und Unterschiede in Informationen zu entdecken, macht sie zur idealen Lösung für die explorative Datenanalyse, Kundensegmentierung und Bilderkennung.
Folgende Algorithmen sind Beispiele für unsupervised Learning \cite{geron2019hands-on}:
\begin{itemize}
	\item K-Means
	\item DBSCAN
	\item Hierarchical Cluster Analysis (HCA)
	\item Principal Component Analysis (PCA)
	\item Kernel PCA
	\item Locally-Linear Embedding (LLE)
	\item Apriori
	\item Eclat
\end{itemize}
Clustering, Assoziationsanalyse und Dimensionalitätsreduktion sind die drei Hauptaufgaben von unsupervised Machine Learning \cite{unsupervisedibm}.
\subsection{Clustering}
Beim Clustering geht es darum, die Population oder die Datenpunkte in eine Reihe von Gruppen aufzuteilen, so dass die Datenpunkte in denselben Gruppen anderen Datenpunkten in derselben Gruppe ähnlicher und den Datenpunkten in anderen Gruppen unähnlicher sind \cite{clusteringgeeks}.
Es werden ungelabelte Daten auf der Grundlage ihrer Ähnlichkeiten oder Differenzen in verschiedene Gruppen aufgeteilt \cite{unsupervisedibm}. 
Anwendungsgebiete für Clustering sind beispielsweise Bücher die je nach Titel und Inhalt in verschiedene Gruppen eingeteilt werden oder Pflanzen und Tiere welche in Spezies aufgeteilt werden (siehe Abbildung ~\ref{fig:unsupervised}) \cite{clusteringgeeks}.
\subsection{Assoziationsanalyse}
Die Assoziationsanalyse ist eine Methode um herauszufinden welche Muster (Beziehungen, Korrelationen, Strukturen, ...) es in den Datensätzen gibt \cite{associationmedium}.
Diese Methode wird häufig für Warenkorbanalysen verwendet, um ein besseres Verständis über die Beziehung zwischen den Produkten zu bekommen. 
Beispiele davon sind z.B. auf Amazon die "Kunden, die diesen Artikel gekauft haben, kauften auch:" Anzeige oder die Spotify "Discover Weekly" Playlist. \cite{unsupervisedibm}
\subsection{Dimensionalitätsreduktion}
Während mehr Daten grundsätzlich zu genaueren Ergebnissen führen können, so kann dies auch die Leistung von Algorithmen für machine Learning beeinträchtigen (z.B. overfitting) und die Visualisierung von Datensätzen erschweren \cite{unsupervisedibm}.
Bei der Dimensionalitätsreduktion geht es darum, die Variablen in den Daten auf die wesentlichen und zielführenden zu beschränken (z.B. werden redundante oder noise Features entfernt) \cite{unsuperviseddatasolut}, wobei die Integrität der Daten so weit wir möglich erhalten bleiben soll \cite{unsupervisedibm}.
Es kann für das bereinigen von Daten oder auch für das Hervorheben von Features verwendet werden, da die Daten dabei von hochdimensionalem Featureraum in niedrigdimensionalem Featureraum transformiert werden \cite{dimensionalityneptune}.

\section{Semi-supervised Learning}
\label{sec:semisupervised}
Um die Schwierigkeiten vom Erstellen von großen gelabelten Datensätzen entgegenzuwirken gibt es eine Methode bei der ein kleiner Anteil gelabelte Daten, der Großteil jedoch ungelabelte Daten sind.
Dieese Methode wird als semi-supervised Learning bezeichnet, welche die Benefits von unsupervised und supervised kombiniert. \cite{semisuperviseddatarobot}
Der Algorithmus wird initial mit den wenig gelabelten Daten trainiert und kann somit iterativ mehr und mehr an die ungelabelten Daten angewandt werden.
Self-training und Co-training sind zwei Ansätze für semi-supervised learning. \cite{semisupervisedalexsoft}
\subsection{Self-training}
Self-training ist eines der einfachsten Beispiele für semi-supervised learning und ist ein Prozedere einen supervised learning Ansatz in semi-supervised umzuwandeln \cite{semisupervisedalexsoft}.
Der straightforward Ansatz wird anhand folgendem Beispiel erklärt:
\begin{enumerate}
	\item Die gelabelten Daten werden für das Trainieren des Models herangenommen \cite{selftrainingtowardsdatasience}
	\item Dieses Model wird dann für die Vorhersage von ungelabelten Daten verwendet \cite{selftrainingtowardsdatasience}
	\item Es werden Ergebnisse, welche dem zuvor bestimmten Kriterium entsprechen (z.B. >90\% accuracy), mit pseduo-labels verzehrt und mit den bereits gelabelten Daten kombiniert \cite{selftrainingtowardsdatasience}
	\item Das Model wird nun mit dem neuen Pool an gelabelten Daten trainiert \cite{selftrainingtowardsdatasience}
	\item Der ganze Prozess wird nun durchiteriert bis entweder alle Daten gelabelt sind oder die spezifizierte Maximalanzahl an Iterationen erreicht wird \cite{selftrainingtowardsdatasience}
\end{enumerate}
Die Performance von dem Self-training Ansatz variiert von Datensatz zu Datensatz und es gilt abzuwägen ob sie im Vergeleich zu dem supervised Ansatz eine Verbesserung erzielt \cite{semisupervisedalexsoft}. 
\subsection{Co-training}

\section{Reinforcement Learning}
\label{sec:reinforcement}
tbd.

\section{Neuronale Netzwerke}
\label{sec:neuronalnetworks}
tbd.

\chapter{Bildbezogenes Machine Learning}
\label{sec:imagerelatedml}
tbd.

\section{Wie computer sehen}
\label{sec:howcomputersee}
tbd.

\section{Bilderkennung und Klassifizierung}
\label{sec:recognitionandclassification}
tbd.

\section{Algorithmen für Bildähnlichkeitserkennung}
\label{sec:algorithmsimagesimilarity}

\chapter{Prototyp zur Bildähnlichkeitserkennung von Markenlogos}
\label{chap:prototype}

\section{Daten}
\label{sec:data}

\section{Bildvorverarbeitung}
\label{sec:imagepreprocessing}

\section{Algorithmus}
\label{sec:algorithm}





%\chapter{Examples}
%\label{chap:intro}
%Textkörper mit Bild
%
%\begin{figure}[htbp]
%	\centering
%		\includegraphics[height=5cm]{images/buecher.png}
%	\caption{Ein Stapel Bücher}
%	\label{fig:buecher}
%\end{figure}
%
%
%Textkörper Fortsetzung mit Verweis auf den wundervollen Stapel Bücher in Abbildung \ref{fig:buecher}. 
%
%
%\section{Unterkapitel 1}
%\label{sec:Unterkapitel1}
%
%Textkörper mit Formel:
%
%\begin{equation}
%U(j\omega)=\int^{\infty}_{-\infty}{u(t) \cdot e^{-j\omega t}dt}
%\label{form:form1}
%\end{equation}
%
%Textkörper Fortsetzung mit Verweis auf Formel \ref{form:form1}. Und nicht zu vergessen: es gibt auch noch eine tolle Abbildung in Kapitel \ref{chap:intro}, nämlich Abbildung \ref{fig:buecher}. 
%
%
%\subsection{Unter-Unterkapitel 11}
%\label{sec:UnterUnterkapitel11}
%
%Textkörper mit direktem Zitat und Seitenanzahl:
%``It would be very easy to show how technical or report writing differed from other writing'' \cite[p.~3]{young2002technical}.
%
%\subsection{Unter-Unterkapitel 12}
%\label{sec:UnterUnterkapitel12}
%
%Textkörper mit Referenzen:
%Für weiterführende Informationen zum wissenschaftlichen Schreiben siehe "J. Schimel, Writing Science" \cite{schimel2012writing}. Es wird empfohlen den Sprachleitfaden der FH Campus Wien \cite{alker2006} zu berücksichtigen und die Checkliste für wissenschafltiches Schreiben \cite{petz2018} zu verwenden. Beide Leitfäden sind im FH Portal zu finden.
%
%\chapter{Kapitel 2}
%\label{chap:back}
%
%Textkörper mit noch einem Bild
%
%\begin{figure}[htbp]
%	\centering
%		\includegraphics{images/birne}
%	\caption{Eine Glühbirne}
%	\label{fig:birne}
%\end{figure}
%
%
%
%\section{Unterkapitel 21}
%\label{sec:Unterkapitel21}
%
%Textkörper mit Tabelle.
%
%\begin{table*}[htbp]
%	\centering
%		\begin{tabular}{|l|c|r|}
%		\hline
%		\rowcolor[gray]{0.9}
%		Spalte 1 & Spalte 2 & Spalte 3 \\
%		\hline
%		Affen & Giraffen & Löwen \\
%		Apfel & Birnen & Bananen \\
%		Irgend & et & was \\
%		\hline	
%		\end{tabular}
%	\caption{Beispiel für eine Tabelle}
%	\label{tab:BeispielFuerEineTabelle}
%\end{table*}
%
%Man beachte die Gegenüberstellung in Tabelle \ref{tab:BeispielFuerEineTabelle}.
%
%%Online Tabellengenerator für Latex: https://www.tablesgenerator.com/
%
%\section{Unterkapitel 23}
%\label{sec:Unterkapite23}
%
%Aufzählungen:
%
%Nummeriert:
%
%\begin{enumerate}
%	\item Punkt 1
%	\item Punkt 2
%\end{enumerate}
%
%Mit Bullet Points:
%
%\begin{itemize}
%	\item Punkt 1
%	\item Punkt 2
%\end{itemize}
%
%Mit Beschreibungen:
%
%\begin{description}
%	\item[Item 1] das ist der 1.Punkt
%	\item[Item 2] und das der 2.
%\end{description}
%
%
%Auch Programmcodes können an entsprechender Stelle eingefügt werden, man beachte dazu auch Listing \ref{lst:conv}.
%
%% see also http://mirror.easyname.at/ctan/macros/latex/contrib/listings/listings.pdf for options
%
%\begin{lstlisting}[frame=lines, caption=Simple Listing, captionpos=b, label = lst:conv, language=C, showstringspaces=false]
%#include <stdio.h>
%int main()
%{
%	int i, n, t1 = 0, t2 = 1, nextTerm;
%
%	printf("Enter the number of terms: ");
%	scanf("%d", &n);
%
%	printf("Fibonacci Series: ");
%
%	for (i = 1; i <= n; ++i)
%	{
%		printf("%d, ", t1);
%		nextTerm = t1 + t2;
%		t1 = t2;
%		t2 = nextTerm;
%	}
%	return 0;
%}
%\end{lstlisting}
%
%Und zuguterletzt, Formeln mitten im Fliesstext, wie z.B. $a^2+b^2=c^2$, in einem Absatz.

%\newpage
%\chapter{Related Work}

\newpage
\chapter{Diskussion der Ergebnise}

\newpage
\chapter{Conclusio}

\newpage
\chapter{Ausblick}

\newpage

% --- Bibliography ------------------------------------------------------

%IEEE Citation [1]
\bibliographystyle{IEEEtran}
%for alphanumeric citation eg.: [ABC19]
%\bibliographystyle{alpha}

% List references I definitely want in the bibliography,
% regardless of whether or not I cite them in the thesis.

\newpage
\addcontentsline{toc}{chapter}{Bibliographie}
\bibliography{testBib}

\newpage

% --- List of Figures ----------------------------------------------------

\addcontentsline{toc}{chapter}{Abbildungen}
\listoffigures


% --- List of Tables -----------------------------------------------------

\newpage
\addcontentsline{toc}{chapter}{Tabellen}
\listoftables

% --- Appendix A -----------------------------------------------------

\newpage
\appendix
\backmatter
\begin{appendices}
\chapter{Appendix}

(Hier können Schaltpläne, Programme usw. eingefügt werden.)

\clearpage
\end{appendices}

\end{document}
